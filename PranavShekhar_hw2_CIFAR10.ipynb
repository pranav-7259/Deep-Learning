{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl3eIEYFkgP7"
      },
      "source": [
        "<h1 align='center'><b><font color ='pickle'>HW2_Softmax_Scratch_CIFAR10</b></h1>\n",
        "\n",
        "- Task1 (5 Points)\n",
        " > - Complete the `# code here` in all the code cells below.\n",
        "  > - Make sure you run all the cells even if the cells do not have `# code here`\n",
        " > - For the first task use learning rate = 0.005\n",
        "\n",
        "- Task 2 (5 Points)\n",
        " > -  First make sure that Task1 is running without any errors\n",
        " > - For this task, you only need to make changes to cell in HyperParameter Section\n",
        " > - You will run all the cells including and after Hyperparamter section\n",
        " > - Try following Learning Rates : 0.001, 0.01, 0.05, 0.5\n",
        " > - Make sure in wandb.init() - you change the run names as well - L0.001, L0.01, L0.05, L0.5\n",
        " > - Do not create separate notebooks. Run all the experiment using this notebook only. Change the values of hyperparamter and run the  cells including and after Hyperparamter section.\n",
        " > - Go to wandb account and make the project public. By default Weights & Biases projects are private, which means other users won’t be able to view your work. You can edit this default on your settings page.\n",
        " > - In the cell of the notebook provide the link to your project (https://wandb.ai/user-name/project-name)\n",
        " > - In the last cell provide conclusion on how the test accuracy is changing with change in learning rate\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0HXlZjttb9Q"
      },
      "source": [
        "# <Font color = 'pickle'>**Install/Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:32.246958Z",
          "iopub.status.busy": "2022-09-14T05:31:32.246604Z",
          "iopub.status.idle": "2022-09-14T05:31:32.253649Z",
          "shell.execute_reply": "2022-09-14T05:31:32.253006Z",
          "shell.execute_reply.started": "2022-09-14T05:31:32.246871Z"
        },
        "id": "-h5a-vtFb738",
        "outputId": "85c74327-cbcb-41ae-fc8a-c98f68b890ed",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n"
          ]
        }
      ],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "  print('Running on CoLab')\n",
        "else:\n",
        "  print('Not running on CoLab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:32.254709Z",
          "iopub.status.busy": "2022-09-14T05:31:32.254493Z",
          "iopub.status.idle": "2022-09-14T05:31:32.257490Z",
          "shell.execute_reply": "2022-09-14T05:31:32.257106Z",
          "shell.execute_reply.started": "2022-09-14T05:31:32.254693Z"
        },
        "id": "q4OpOEo0QktF",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8281ee0-81d2-4dcc-8017-5808f2e3612b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.3-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 52.9 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 53.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 58.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 55.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 47.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 49.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 45.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 54.3 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 26.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=d8f76144221542761894cbe07746b8b1b0933e841548f72a801044ddf57a85ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.3\n"
          ]
        }
      ],
      "source": [
        "# Install wandb and update it to the latest version\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install wandb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:32.258187Z",
          "iopub.status.busy": "2022-09-14T05:31:32.258002Z",
          "iopub.status.idle": "2022-09-14T05:31:32.261431Z",
          "shell.execute_reply": "2022-09-14T05:31:32.261057Z",
          "shell.execute_reply.started": "2022-09-14T05:31:32.258172Z"
        },
        "id": "m7C0tvyKoy6f",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30f70f8-4555-42fb-fe73-6033ec703ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:32.262927Z",
          "iopub.status.busy": "2022-09-14T05:31:32.262590Z",
          "iopub.status.idle": "2022-09-14T05:31:32.896213Z",
          "shell.execute_reply": "2022-09-14T05:31:32.895577Z",
          "shell.execute_reply.started": "2022-09-14T05:31:32.262910Z"
        },
        "id": "TqYqOtp5yluv",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import wandb\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %env 'WANDB_NOTEBOOK_NAME' 'Hw2_Softmax_Scratch_CIFAR10.ipynb'\n",
        "# in the above line we are specyfying the jupyter(colab) notebook name for wandb\n",
        "# Login to W&B\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "TTzXg_GSEb88",
        "outputId": "63db635c-e2a0-46d4-b02a-f55b8094aba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: 'WANDB_NOTEBOOK_NAME'='Hw2_Softmax_Scratch_CIFAR10.ipynb'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(name = \"Hw2_Softmax_Scratch_CIFAR10.ipynb\", project = 'Deep_Learning_Class_UTD')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "AbYP6ryPG42Y",
        "outputId": "468b131f-9b49-454f-9a5e-fb44b9ad3a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpranavshekhar2\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220921_183607-2n2s4on2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/pranavshekhar2/Deep_Learning_Class_UTD/runs/2n2s4on2\" target=\"_blank\">Hw2_Softmax_Scratch_CIFAR10.ipynb</a></strong> to <a href=\"https://wandb.ai/pranavshekhar2/Deep_Learning_Class_UTD\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/pranavshekhar2/Deep_Learning_Class_UTD/runs/2n2s4on2?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fc6fbdc7f10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17xctemopjdA"
      },
      "source": [
        "# <Font color = 'pickle'>**CIFAR10 Dataset**\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "Categories present in the dataset:\n",
        "\n",
        " <font color = 'indianred'>**['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', horse', 'ship', 'truck']**</font>\n",
        "\n",
        "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks\n",
        "\n",
        "Let us download the dataset using some built-in functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1VfYqgk9nAD"
      },
      "source": [
        "We will first convert the images in the dataset to pytorch tensors using torchvision.transforms and then normalize them.\n",
        "\n",
        "Next, we will use torchvision.datasets for downloading the CIFAR10 datasets and apply transform that we defines earlier. \n",
        "\n",
        "- `trainset` conains the training data\n",
        "- `testset` contains the testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:32.901939Z",
          "iopub.status.busy": "2022-09-14T05:31:32.901560Z",
          "iopub.status.idle": "2022-09-14T05:31:32.906014Z",
          "shell.execute_reply": "2022-09-14T05:31:32.905526Z",
          "shell.execute_reply.started": "2022-09-14T05:31:32.901919Z"
        },
        "id": "zd6c5IGa_iUl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This is the path where we will downlaod and save data\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    data_folder = Path('/content/drive/MyDrive/Deep_Learning_UTD/Dataset')\n",
        "else:\n",
        "    data_folder = Path('/home/harpreet/Insync/google_drive_shaannoor/data/datasets')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTrbf15aROgj"
      },
      "source": [
        "## <Font color = 'pickle'>**Train and Test Dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:32.907485Z",
          "iopub.status.busy": "2022-09-14T05:31:32.907159Z",
          "iopub.status.idle": "2022-09-14T05:31:33.879861Z",
          "shell.execute_reply": "2022-09-14T05:31:33.879311Z",
          "shell.execute_reply.started": "2022-09-14T05:31:32.907430Z"
        },
        "id": "fW8R-Djbrd05",
        "outputId": "c6b303bc-4a65-4b51-e99d-7a4504e4005d",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Transform to convert images to pytorch tensors\n",
        "trans1 = transforms.ToTensor()\n",
        "\n",
        "# Transform to normalize the data\n",
        "# The mean and std are based on train subset which we will create below\n",
        "trans2 = transforms.Normalize((0.49, 0.482, 0.447), (0.247, 0.244, 0.262))\n",
        "trans = transforms.Compose([trans1, trans2])\n",
        "\n",
        "# Download the training_validation data (we will create two subsets - trainset and valset frpm this)\n",
        "train_val_set = torchvision.datasets.CIFAR10(root = data_folder,\n",
        "                                             train = True,\n",
        "                                             transform= trans,\n",
        "                                             download=True)\n",
        "\n",
        "# Download the testing data\n",
        "testset = torchvision.datasets.CIFAR10(root = data_folder,\n",
        "                                       train = False,\n",
        "                                       transform = trans,\n",
        "                                       download= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_ICobccV--y"
      },
      "source": [
        "## <Font color = 'pickle'>**Split train set to train/validation set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.880703Z",
          "iopub.status.busy": "2022-09-14T05:31:33.880513Z",
          "iopub.status.idle": "2022-09-14T05:31:33.884916Z",
          "shell.execute_reply": "2022-09-14T05:31:33.883971Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.880686Z"
        },
        "id": "mm5_iI3sjdwB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def split_dataset(base_dataset, fraction, seed):\n",
        "    split_a_size = int(fraction * len(base_dataset))\n",
        "    split_b_size = len(base_dataset) - split_a_size\n",
        "    return torch.utils.data.random_split(base_dataset, [split_a_size, split_b_size], generator=torch.Generator().manual_seed(seed)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.886443Z",
          "iopub.status.busy": "2022-09-14T05:31:33.886137Z",
          "iopub.status.idle": "2022-09-14T05:31:33.892040Z",
          "shell.execute_reply": "2022-09-14T05:31:33.891551Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.886406Z"
        },
        "id": "8X5iQ2zpkcV1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainset, validset = split_dataset(train_val_set,0.8,10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the transforms are not applied, we will manually first divide by 255\n",
        "# we will then get the mean and std dev \n",
        "# the images are still in mumpy with the shape (number of images, H, W, Channels)\n",
        "# Since we need mean, std dev \n",
        "train_data = train_val_set.data[trainset.indices]/255\n",
        "train_data.shape\n",
        "print(train_data.mean(axis = (0,1,2)))\n",
        "print(train_data.std(axis = (0,1,2)))"
      ],
      "metadata": {
        "id": "rG_W_NIqy5Ov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a8d78d-0aa7-483a-fc97-493f8a13c40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.49114078 0.48191055 0.44641415]\n",
            "[0.24707852 0.24355821 0.26162066]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0ipdb9rXovr"
      },
      "source": [
        "## <Font color = 'pickle'>**Check inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.893256Z",
          "iopub.status.busy": "2022-09-14T05:31:33.892741Z",
          "iopub.status.idle": "2022-09-14T05:31:33.896644Z",
          "shell.execute_reply": "2022-09-14T05:31:33.895773Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.893234Z"
        },
        "id": "SEafSvdbxaUW",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e9b618-590a-4777-ddc4-fd282b912146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataset.Subset'>\n",
            "<class 'torchvision.datasets.cifar.CIFAR10'>\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "print(type(trainset), type(trainset.dataset), type(trainset.indices), sep ='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.897605Z",
          "iopub.status.busy": "2022-09-14T05:31:33.897261Z",
          "iopub.status.idle": "2022-09-14T05:31:33.906285Z",
          "shell.execute_reply": "2022-09-14T05:31:33.905795Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.897587Z"
        },
        "id": "vugZuVfwvoeT",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de65d29-8897-4508-e3cc-19ea183b1e0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[46937, 45069, 32498, 25031, 16172]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "trainset.indices[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.907470Z",
          "iopub.status.busy": "2022-09-14T05:31:33.906954Z",
          "iopub.status.idle": "2022-09-14T05:31:33.910442Z",
          "shell.execute_reply": "2022-09-14T05:31:33.909908Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.907450Z"
        },
        "id": "wGXxzrChyQYp",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d7c8b4-3dde-4cf5-a8a4-e9032b408c4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40000\n",
            "50000\n",
            "40000\n"
          ]
        }
      ],
      "source": [
        "print(len(trainset), len(trainset.dataset), len(trainset.indices), sep ='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.913561Z",
          "iopub.status.busy": "2022-09-14T05:31:33.913311Z",
          "iopub.status.idle": "2022-09-14T05:31:33.917012Z",
          "shell.execute_reply": "2022-09-14T05:31:33.916531Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.913540Z"
        },
        "id": "w1Zov4McmuN-",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d46934d-6bfb-4df9-ae42-6b9bdc5cb98c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Shape of training data\n",
        "len(trainset.indices), len(validset.indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.917820Z",
          "iopub.status.busy": "2022-09-14T05:31:33.917642Z",
          "iopub.status.idle": "2022-09-14T05:31:33.968484Z",
          "shell.execute_reply": "2022-09-14T05:31:33.968001Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.917802Z"
        },
        "id": "Ci1h1FlYvMaa",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35cdc48-5021-45e1-b5b2-998f02a88438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 32, 32, 3)\n",
            "(40000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "#Both the functions are similar\n",
        "\n",
        "print(train_val_set.data[trainset.indices].shape)\n",
        "print(trainset.dataset.data[trainset.indices].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.969502Z",
          "iopub.status.busy": "2022-09-14T05:31:33.969097Z",
          "iopub.status.idle": "2022-09-14T05:31:33.978382Z",
          "shell.execute_reply": "2022-09-14T05:31:33.977951Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.969483Z"
        },
        "id": "f1MpLXsTvdSo",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc2222a-2c04-4e68-940c-c1f2b6860543"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_val_set.data[validset.indices].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.979326Z",
          "iopub.status.busy": "2022-09-14T05:31:33.978980Z",
          "iopub.status.idle": "2022-09-14T05:31:33.982318Z",
          "shell.execute_reply": "2022-09-14T05:31:33.981918Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.979308Z"
        },
        "id": "JmgUaxgu_RqQ",
        "outputId": "183d366b-6ce4-4a1c-9500-8701f8fc827f",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Shape of testing data\n",
        "testset.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:33.983113Z",
          "iopub.status.busy": "2022-09-14T05:31:33.982940Z",
          "iopub.status.idle": "2022-09-14T05:31:34.068209Z",
          "shell.execute_reply": "2022-09-14T05:31:34.067826Z",
          "shell.execute_reply.started": "2022-09-14T05:31:33.983096Z"
        },
        "id": "OS5QMGxmlqE-",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8747034f-da5e-4440-bf3e-9d3aad476d4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# check the max value of inputs - the transformation are not yet applied.\n",
        "# the transofrmation are applied iteratively on batches \n",
        "# when we craete batch by iterating over dataloader\n",
        "train_val_set.data[trainset.indices].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.069226Z",
          "iopub.status.busy": "2022-09-14T05:31:34.068735Z",
          "iopub.status.idle": "2022-09-14T05:31:34.185708Z",
          "shell.execute_reply": "2022-09-14T05:31:34.185322Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.069206Z"
        },
        "id": "Gs5yKgGumIwN",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ce48a3-d724-44bc-999c-8e18a751ebb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# check the min value of inputs\n",
        "train_val_set.data[trainset.indices].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-JCMTUfX5vp"
      },
      "source": [
        "## <Font color = 'pickle'>**Check Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.707504Z",
          "iopub.status.busy": "2022-09-14T05:31:34.707345Z",
          "iopub.status.idle": "2022-09-14T05:31:34.713267Z",
          "shell.execute_reply": "2022-09-14T05:31:34.712887Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.707476Z"
        },
        "id": "_W3Xmg7zXQAE",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d69b32b-59c8-4759-d834-ef2216ba02b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40000])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# check target values for train set\n",
        "train_val_targets = torch.tensor(train_val_set.targets)\n",
        "train_val_targets[trainset.indices].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.714070Z",
          "iopub.status.busy": "2022-09-14T05:31:34.713751Z",
          "iopub.status.idle": "2022-09-14T05:31:34.719290Z",
          "shell.execute_reply": "2022-09-14T05:31:34.718806Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.714055Z"
        },
        "id": "rRsK8ZYMXR38",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3a9939-00ba-449c-c0ac-1b2cb960be89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Unique Target values\n",
        "train_val_targets[trainset.indices].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.720004Z",
          "iopub.status.busy": "2022-09-14T05:31:34.719821Z",
          "iopub.status.idle": "2022-09-14T05:31:34.723597Z",
          "shell.execute_reply": "2022-09-14T05:31:34.723193Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.719990Z"
        },
        "id": "f36Yu2AcwjG-",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b5f6212-abcc-4c3c-f0cd-0f53c80b7771"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "train_val_targets[validset.indices].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.724400Z",
          "iopub.status.busy": "2022-09-14T05:31:34.724099Z",
          "iopub.status.idle": "2022-09-14T05:31:34.727807Z",
          "shell.execute_reply": "2022-09-14T05:31:34.727417Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.724387Z"
        },
        "id": "t-axZSrQwlMk",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b0e7d5a-a363-4c20-a3c0-2722045d0915"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "torch.tensor(testset.targets).unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5PslDp5R7Ff"
      },
      "source": [
        "# <Font color = 'pickle'>**Data Loaders**\n",
        "\n",
        "The next step is to create dataloader for train, valid, and test set using pytorch dataloader. This will be an iterator that will provide dataset in batches.  Let's keep batch size as 256. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.728485Z",
          "iopub.status.busy": "2022-09-14T05:31:34.728312Z",
          "iopub.status.idle": "2022-09-14T05:31:34.731405Z",
          "shell.execute_reply": "2022-09-14T05:31:34.731015Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.728471Z"
        },
        "id": "gEHKwmX_ATOt",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Initializing the batch size\n",
        "batch_size = 256\n",
        "\n",
        "# Creating data loader for train set\n",
        "train_loader = torch.utils.data.DataLoader(dataset= trainset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(dataset = validset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = False)\n",
        "\n",
        "# Creating data loader for test set\n",
        "test_loader = torch.utils.data.DataLoader(dataset = testset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.732061Z",
          "iopub.status.busy": "2022-09-14T05:31:34.731895Z",
          "iopub.status.idle": "2022-09-14T05:31:34.735150Z",
          "shell.execute_reply": "2022-09-14T05:31:34.734764Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.732047Z"
        },
        "id": "SrO2i0utr2fS",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d3a492-ffcf-4346-b690-c80b362b5402"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# check number of batches\n",
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.735800Z",
          "iopub.status.busy": "2022-09-14T05:31:34.735634Z",
          "iopub.status.idle": "2022-09-14T05:31:34.739249Z",
          "shell.execute_reply": "2022-09-14T05:31:34.738864Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.735786Z"
        },
        "id": "KSYReXcBsEjs",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a0d3dd2-9b86-49b4-de27-c0f1d1ce65c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# check total training examples\n",
        "len(train_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.739907Z",
          "iopub.status.busy": "2022-09-14T05:31:34.739739Z",
          "iopub.status.idle": "2022-09-14T05:31:34.785349Z",
          "shell.execute_reply": "2022-09-14T05:31:34.784863Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.739890Z"
        },
        "id": "JGIeEEzEjRlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66edf816-1603-4544-fb62-1ff3d10b5d32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of inputs is :torch.Size([256, 3, 32, 32])\n",
            "\n",
            "max input value  :2.122950792312622\n",
            "\n",
            "min input value  :-1.983805775642395\n",
            "\n",
            "mean input value  :0.03678758814930916\n",
            "\n",
            "std input value  :1.017852783203125\n",
            "\n",
            "shape of targets is :torch.Size([256])\n",
            "\n",
            "inputs  :tensor([[ 1.3186,  1.3980,  1.5726,  1.1916, -0.4438],\n",
            "        [ 1.3344,  1.4773,  1.6202,  1.4615,  0.0961],\n",
            "        [ 1.3344,  1.4456,  1.5567,  1.6044,  0.9852],\n",
            "        [ 1.3662,  1.3980,  1.4456,  1.4773,  1.4932],\n",
            "        [ 1.2868,  1.3662,  1.3980,  1.4297,  1.4456]])\n"
          ]
        }
      ],
      "source": [
        "# check inputs and outputs \n",
        "for input, target in train_loader:\n",
        "  print(f'shape of inputs is :{input.shape}')\n",
        "  print(f'\\nmax input value  :{input.max()}')\n",
        "  print(f'\\nmin input value  :{input.min()}')\n",
        "  print(f'\\nshape of targets is :{target.shape}')\n",
        "  print(f'\\ninputs  :{input[0, 0, 5:10, 5:10]}')\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the mean and std for the 1st batch for each of the channels\n",
        "\n",
        "for input, target in train_loader:\n",
        "  for i in range(3):  \n",
        "    print(f'\\nmean input value of channel {i}  :{input[:,i,:,:].mean()}')\n",
        "    print(f'\\nstd input value of channel {i}  :{input[:,i,:,:].std()}')\n",
        "  \n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngFzGxvZlsHN",
        "outputId": "35d4fbb3-ab34-44b5-fdd8-00d365e45ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "mean input value of channel 0  :0.025842268019914627\n",
            "\n",
            "std input value of channel 0  :1.0074737071990967\n",
            "\n",
            "mean input value of channel 1  :0.025880778208374977\n",
            "\n",
            "std input value of channel 1  :0.9934594035148621\n",
            "\n",
            "mean input value of channel 2  :0.006211657077074051\n",
            "\n",
            "std input value of channel 2  :0.9830087423324585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size = 5, color = 'indianred' > What values you observe for mean and std for the batch and why? </font>\n",
        "\n",
        "<font size = 4, color = 'indianred' >\n",
        "Type Answer Below </font>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oh0hOi17v95q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The values have been transformed and normalized while using the dataloader and we get mean close to **0** and std close to **1** as part of normalization step."
      ],
      "metadata": {
        "id": "x6DHiv_PAcx4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04zmdTe-EDeB"
      },
      "source": [
        "# <Font color = 'pickle'>**Visualize the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.786301Z",
          "iopub.status.busy": "2022-09-14T05:31:34.786095Z",
          "iopub.status.idle": "2022-09-14T05:31:34.857926Z",
          "shell.execute_reply": "2022-09-14T05:31:34.857498Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.786285Z"
        },
        "id": "1jcbvhvwCvDX"
      },
      "outputs": [],
      "source": [
        "# Get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images[0:50], nrow = 10)\n",
        "\n",
        "# Logging to W&B\n",
        "images = wandb.Image(img_grid, caption = \"Sample images\")\n",
        "images.image\n",
        "\n",
        "wandb.log({\"Sample Images\": [images]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.858890Z",
          "iopub.status.busy": "2022-09-14T05:31:34.858531Z",
          "iopub.status.idle": "2022-09-14T05:31:34.861222Z",
          "shell.execute_reply": "2022-09-14T05:31:34.860856Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.858870Z"
        },
        "id": "C64NLmbjD-Qr"
      },
      "outputs": [],
      "source": [
        "# Define the values for classes\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ60WJKlg3bQ"
      },
      "source": [
        "# <font color = 'pickle'> **Functions to implement Softmax**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D7A5cBeFoAI"
      },
      "source": [
        "Now, we will start implementing our Softmax Regression Model from scratch.\n",
        "\n",
        "We will now create following functions:\n",
        "\n",
        "- **Model**\n",
        "- **Loss Function** \n",
        "- **One Hot Encoding**\n",
        "- **Training Loop for 1 epoch**\n",
        "- **Validation Loop for 1 epoch**\n",
        "- **Model Training** - repeat the training and validation loops for given number of epochs\n",
        "- **Function to get the accuracy given the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLIXu5RaylkZ"
      },
      "source": [
        "## <Font color = 'pickle'>**Function to define Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68CPKJ_Tb74H"
      },
      "source": [
        "It has two steps :\n",
        "- Calculate output as a linerar function of inputs\n",
        "$$o_k^{(i)}  = \\mathbf{x^{(i)}}\\mathbf{w_k} ^T+b_k$$\n",
        "- Apply softmax on output to get probabilities\n",
        "$$\\hat{p_k}^{(i)} = softmax(o_k^{(i)}) = \\frac{e^{o_k^{(i)}}}{\\sum_{j=1}^{K} e^{o_j^{(i)}}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVdm23xz0idF"
      },
      "source": [
        "Softmax operation consists of three steps: \n",
        "- Exponentiate each term.\n",
        "- Sum over each row to get the normalization constant for each example.\n",
        "- Divide each row by its normalization constant.\n",
        "\n",
        "This is given by:\n",
        "\n",
        "We will first define the function for softmax operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.861961Z",
          "iopub.status.busy": "2022-09-14T05:31:34.861772Z",
          "iopub.status.idle": "2022-09-14T05:31:34.864759Z",
          "shell.execute_reply": "2022-09-14T05:31:34.864402Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.861946Z"
        },
        "id": "LNJY8GBipO2q",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def softmax(output):\n",
        "    \"\"\" \n",
        "    Function to calculate softmax.\n",
        "    Input: Tensor.\n",
        "    Output: Softmax of tensor.\n",
        "    \"\"\"\n",
        "\n",
        "    # Numerator\n",
        "    num = torch.exp(output)\n",
        "\n",
        "    # Denominator\n",
        "    denom = num.sum(axis = 1, keepdim= True)\n",
        "\n",
        "    # Return the softmax value\n",
        "    return num / denom  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.865571Z",
          "iopub.status.busy": "2022-09-14T05:31:34.865294Z",
          "iopub.status.idle": "2022-09-14T05:31:34.868289Z",
          "shell.execute_reply": "2022-09-14T05:31:34.867925Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.865555Z"
        },
        "id": "0pH7KccxpO0l",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def model(X):\n",
        "    \"\"\" \n",
        "    Softmax Regression Model.\n",
        "    Input: Features, Weight, bias\n",
        "    Output: Predicted labels.\n",
        "    \"\"\"\n",
        "\n",
        "    # Reshape X so that matrix multiplication is possible between Weights and X\n",
        "    \n",
        "    #Weights - Output to Input. We want the input shape for X ( Number of variables ( pixels) )\n",
        "    #Output - 10 classes\n",
        "    #Shape of W - 10 * (3 * 32 * 32 )\n",
        "    #Shape of each row of X - (3 *  32 * 32)\n",
        "\n",
        "    #X, W.T -> (1 * No of pixels) , ( No of pixels, 10) -> (1,10)\n",
        "    #b = (1,10)  \n",
        "\n",
        "\n",
        "    X = X.reshape(-1, W.shape[1])\n",
        "    \n",
        "    # Now we will perform the operation to get our equation y = Xw + b\n",
        "    Y = torch.matmul(X,W.T) + b\n",
        "\n",
        "    # Now we will return the softmax of our predictions\n",
        "    return softmax(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVS8_YVHyr5T"
      },
      "source": [
        "## <Font color = 'pickle'>**Loss Function**\n",
        "\n",
        "We will be using cross-entropy loss.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.868960Z",
          "iopub.status.busy": "2022-09-14T05:31:34.868782Z",
          "iopub.status.idle": "2022-09-14T05:31:34.872661Z",
          "shell.execute_reply": "2022-09-14T05:31:34.872197Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.868946Z"
        },
        "id": "j-RnWvExpOyy",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def cross_entropy(ypred, y):\n",
        "    \"\"\" \n",
        "    Function to calculate Cross Entropy loss.\n",
        "    Input: Predicted labels and actual labels.\n",
        "    Output: Loss.\n",
        "    \"\"\" \n",
        "    return - torch.log(ypred[range(len(ypred)), y] + 1e-7).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMsNKeyjy0GU"
      },
      "source": [
        "## <Font color = 'pickle'>**One-Hot Encoding- Encode Labels**\n",
        "\n",
        "A one-hot encoding is a vector with as many components as the labels. The component corresponding to particular instance’s label is set to 1 and all other components are set to 0. \n",
        "\n",
        "Suppose we have a dataset with 3 classes `{cat, dog, parrot}`. Now, if an image is a dog, it's one-hot encoded vector will be `{0, 1, 0}`.\n",
        "\n",
        "One-hot encoded vector for the all the 3 different classes:\n",
        "\n",
        "cat: {1, 0, 0}\n",
        "\n",
        "dog: {0, 1, 0}\n",
        "\n",
        "parrot: {0, 0, 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.873593Z",
          "iopub.status.busy": "2022-09-14T05:31:34.873281Z",
          "iopub.status.idle": "2022-09-14T05:31:34.876497Z",
          "shell.execute_reply": "2022-09-14T05:31:34.876103Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.873576Z"
        },
        "id": "K5R3ELkGpOvH",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def one_hot_labels(labels, num_labels, device):\n",
        "  \"\"\" \n",
        "  Function to convert labels to one-hot vectors.\n",
        "  Input: labels, number of labels, device\n",
        "  \n",
        "  Output: One-hot encoded labels.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  # Construct a tensor of size : (number of observations, number of labels)\n",
        "  y = torch.zeros((len(labels), num_labels), device = device)\n",
        "\n",
        "  # Iterate over labels and create one-hot vectors according to label value\n",
        "  for i, l in enumerate(labels):\n",
        "      y[i][l] = 1\n",
        "\n",
        "  # Return one-hot encoded vector of labels\n",
        "  return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqI_o6qwy6lb"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Training  Loops**\n",
        "\n",
        "**Model Training** involves five steps: \n",
        "\n",
        "- Step 0: Randomly initialize parameters / weights\n",
        "- Step 1: Compute model's predictions - forward pass\n",
        "- Step 2: Compute loss\n",
        "- Step 3: Compute the gradients\n",
        "- Step 4: Update the parameters\n",
        "- Step 5: Repeat steps 1 - 4\n",
        "\n",
        "Model training is repeating this process over and over, for many **epochs**.\n",
        "\n",
        "We will specify number of ***epochs*** and during each epoch we will iterate over the complete dataset and will keep on updating the parameters.\n",
        "\n",
        "***Learning rate*** and ***epochs*** are known as hyperparameters. We have to adjust the values of these two based on validation dataset.\n",
        "\n",
        "We will now create functions for step 1 to 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.877415Z",
          "iopub.status.busy": "2022-09-14T05:31:34.877103Z",
          "iopub.status.idle": "2022-09-14T05:31:34.882138Z",
          "shell.execute_reply": "2022-09-14T05:31:34.881761Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.877400Z"
        },
        "id": "Pv4x22lZMn5p",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train(train_loader, W, b, learning_rate, loss_function):\n",
        "\n",
        "  \"\"\" \n",
        "  Function for training the model in each epoch\n",
        "  Input: iterator for train dataset, weights and bias, number of outputs, learning rate,\n",
        "  loss function, model.\n",
        "  Output: weights, bias, train loss, train accuracy at end of each epoch\n",
        "  \"\"\"\n",
        "\n",
        "  # Step 0: Randomly initialize parameters / weights - We give this as input to function for first epoch\n",
        "  # In subsequent epochs the function gets the updated weights from last epoch\n",
        "\n",
        "  # Training Loop \n",
        "  # Initialize train_loss at the he start of the epoch\n",
        "  running_train_loss = 0\n",
        "  running_train_correct = 0\n",
        "  #num_outputs = 10\n",
        "  \n",
        "  # Iterate on batches from the dataset using train_loader\n",
        "  for input, targets in train_loader:\n",
        "    \n",
        "    # move inputs and outputs to GPUs\n",
        "    input = input.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # one hot encoding for target variable\n",
        "    target_encoded = one_hot_labels(targets, num_outputs, device = device)\n",
        "\n",
        "    # Step 1: Forward Pass: Compute model's predictions \n",
        "    output = model(input)\n",
        "    \n",
        "    # Step 2: Compute loss\n",
        "    loss = loss_function(output, targets)\n",
        "  \n",
        "    # Get the predicted values\n",
        "    y_pred = torch.argmax(output, dim = 1)\n",
        "\n",
        "    # count number of correct predictions\n",
        "    correct = torch.sum(y_pred == targets)\n",
        "\n",
        "    # Step 3: Backward pass -Compute the gradients\n",
        "    error = output - target_encoded\n",
        "    grad_W = (1/len(input)) * error.T.mm(input.reshape(-1,W.shape[1]))\n",
        "    grad_b = (1/len(input)) * error.sum()\n",
        "\n",
        "    # Step 4: Update the parameters\n",
        "    W -= learning_rate * grad_W\n",
        "    b -= learning_rate * grad_b\n",
        "          \n",
        "    # Add train loss of a batch \n",
        "    running_train_loss += loss.item()\n",
        "\n",
        "    # Add Corect counts of a batch\n",
        "    running_train_correct += correct\n",
        "  \n",
        "  # Calculate mean train loss for the whole dataset for a particular epoch\n",
        "  train_loss = running_train_loss/len(train_loader)\n",
        "\n",
        "  # Calculate accuracy for the whole dataset for a particular epoch\n",
        "  train_acc = running_train_correct/len(train_loader.dataset)\n",
        "  \n",
        "\n",
        "  return W, b, train_loss, train_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeLm-GI5bW2V"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Validation Loops**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.883038Z",
          "iopub.status.busy": "2022-09-14T05:31:34.882720Z",
          "iopub.status.idle": "2022-09-14T05:31:34.887506Z",
          "shell.execute_reply": "2022-09-14T05:31:34.886989Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.883020Z"
        },
        "id": "pHP1WKDessiI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def validate(valid_loader, W, b, loss_function):\n",
        "\n",
        "  \"\"\" \n",
        "  Function for calcuilating loss and prediction for validataion dataset. \n",
        "  Input: iterator for validation dataset, estimated weights and bias at the end of epoch in training loop, \n",
        "  learning rate,   loss function, model\n",
        "  Output: val loss and accuracy for each epoch.\n",
        "  \"\"\"\n",
        "\n",
        "  # Validation loop\n",
        "  # Initialize valid_loss at the he strat of the epoch\n",
        "  \n",
        "  running_val_loss = 0\n",
        "  running_val_correct = 0\n",
        "\n",
        "  for input,targets in valid_loader:\n",
        "\n",
        "    # move inputs and outputs to GPUs\n",
        "    input = input.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # Step 1: Forward Pass: Compute model's predictions \n",
        "    output = model(input)\n",
        "    \n",
        "    # Step 2: Compute loss\n",
        "    loss = loss_function(output, targets)\n",
        "\n",
        "    # Get the predicted values\n",
        "    y_pred = torch.argmax(output, dim = 1)\n",
        "\n",
        "    # count number of correct predictions\n",
        "    correct = torch.sum(y_pred == targets)\n",
        "\n",
        "    # Add val loss of a batch \n",
        "    running_val_loss += loss.item()\n",
        "\n",
        "    # Add correct count for each batch\n",
        "    running_val_correct += correct\n",
        "\n",
        "  # Calculate mean val loss for the whole dataset for a particular epoch\n",
        "  val_loss = running_val_loss/len(valid_loader)\n",
        "\n",
        "  # Calculate accuracy for the whole dataset for a particular epoch\n",
        "  val_acc = running_val_correct/len(valid_loader.dataset)\n",
        "    \n",
        "  return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwF70eqE6n_v"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Model Training**\n",
        "    \n",
        "We will now create a function for step 5 of model training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.888547Z",
          "iopub.status.busy": "2022-09-14T05:31:34.888187Z",
          "iopub.status.idle": "2022-09-14T05:31:34.893965Z",
          "shell.execute_reply": "2022-09-14T05:31:34.893525Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.888528Z"
        },
        "id": "KeCKVgg-5FiZ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train_loop(W, b, num_outputs, train_loader, valid_loader, model, loss_function, epochs, device):\n",
        "    \n",
        "  \"\"\" \n",
        "  Function for training the model and plotting the graph for train & validation loss vs epoch.\n",
        "  Input: iterator for train dataset, initial weights and bias, epochs, learning rate, batch size.\n",
        "  Output: final weights, bias and train loss and validation loss for each epoch.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create lists to store train and val loss at each epoch\n",
        "  train_loss_history = []\n",
        "  valid_loss_history = []\n",
        "  train_acc_history = []\n",
        "  valid_acc_history = []\n",
        "\n",
        "  # Iterate for the given number of epochs\n",
        "  # Step 5: Repeat steps 1 - 4\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Get train loss and accuracy for one epoch\n",
        "    W, b, train_loss, train_acc = train(train_loader, W, b, learning_rate, loss_function)\n",
        "    valid_loss, valid_acc  = validate(valid_loader, W, b , loss_function)\n",
        "    \n",
        "    # Save history of the Losses and accuracy\n",
        "    train_loss_history.append(train_loss)\n",
        "    train_acc_history.append(train_acc)\n",
        "\n",
        "    valid_loss_history.append(valid_loss)\n",
        "    valid_acc_history.append(valid_acc)\n",
        "\n",
        "    # Log the train and valid loss to wandb\n",
        "    wandb.log({f\"Train Loss :\": train_loss})\n",
        "    wandb.log({f\"Train Acc :\": train_acc})\n",
        "\n",
        "    wandb.log({f\"Valid Loss :\": valid_loss})\n",
        "    wandb.log({f\"Valid Acc :\": valid_acc})\n",
        "\n",
        "\n",
        "    # Print the train loss and accuracy for given number of epochs, batch size and number of samples\n",
        "    print(f'Epoch : {epoch+1} / {epochs}')\n",
        "    print(f'Train Loss: {train_loss : .4f} | Train Accuracy: {train_acc * 100 : .4f}%')\n",
        "    print(f'Valid Loss: {valid_loss : .4f} | Valid Accuracy: {valid_acc * 100 : .4f}%')\n",
        "    print()\n",
        "\n",
        "  return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWCLH47azD6j"
      },
      "source": [
        "## <Font color = 'pickle'>**Function for Accuracy and Predictions**\n",
        "\n",
        "Now we have final values for weights and bias after training the model. We will use these values to make predictions on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T05:31:34.894707Z",
          "iopub.status.busy": "2022-09-14T05:31:34.894521Z",
          "iopub.status.idle": "2022-09-14T05:31:34.898629Z",
          "shell.execute_reply": "2022-09-14T05:31:34.898173Z",
          "shell.execute_reply.started": "2022-09-14T05:31:34.894692Z"
        },
        "id": "M6KZqsnqQFVu",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_acc_pred(data_loader, W, b, device):\n",
        "    \n",
        "  \"\"\" \n",
        "  Function to get predictions and accuracy for a given data using estimated model\n",
        "  Input: Data iterator, Final estimated weoights, bias\n",
        "  Output: Prections and Accuracy for given dataset\n",
        "  \"\"\"\n",
        "\n",
        "  # Array to store predicted labels\n",
        "  predictions = torch.Tensor() # empty tensor\n",
        "  predictions = predictions.to(device) # move predictions to GPU\n",
        "\n",
        "  # Array to store actual labels\n",
        "  y = torch.Tensor() # empty tensor\n",
        "  y = y.to(device)\n",
        "\n",
        "  # Iterate over batches from data iterator\n",
        "  for input_, targets in data_loader:\n",
        "    \n",
        "    # move inputs and outputs to GPUs\n",
        "    input_ = input_.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # Calculated the predicted labels\n",
        "    output = model(input_)\n",
        "\n",
        "    # Choose the label with maximum probability\n",
        "    prediction = torch.argmax(output, dim = 1)\n",
        "\n",
        "    # Add the predicted labels to the array\n",
        "    predictions = torch.cat((predictions, prediction)) \n",
        "\n",
        "    # Add the actual labels to the array\n",
        "    y = torch.cat((y, targets)) \n",
        "\n",
        "  # Check for complete dataset if actual and predicted labels are same or not\n",
        "  # Calculate accuracy\n",
        "  acc = (predictions == y).float().mean()\n",
        "\n",
        "  # Return tuple containing predictions and accuracy\n",
        "  return predictions, acc  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVk_RctgdPRP"
      },
      "source": [
        "# <Font color = 'pickle'>**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "execution": {
          "iopub.execute_input": "2022-09-14T06:09:10.201908Z",
          "iopub.status.busy": "2022-09-14T06:09:10.201699Z",
          "iopub.status.idle": "2022-09-14T06:09:15.461499Z",
          "shell.execute_reply": "2022-09-14T06:09:15.461002Z",
          "shell.execute_reply.started": "2022-09-14T06:09:10.201893Z"
        },
        "id": "fZ6ZoM9WaS_M",
        "outputId": "d1279a38-5107-4735-af5b-4fcb0907ad81",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220921_203950-34u9nqca</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/pranavshekhar2/dl22_HW2/runs/34u9nqca\" target=\"_blank\">L_0.5</a></strong> to <a href=\"https://wandb.ai/pranavshekhar2/dl22_HW2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Initialize a new project\n",
        "# 0.001, 0.01, 0.05, 0.5\n",
        "wandb.init(name = \"L_0.5\", project = 'dl22_HW2')\n",
        "\n",
        "# Initialize number of epochs, learning rate and batch size\n",
        "learning_rate = 0.5\n",
        "wandb.log({'learning_rate': learning_rate})\n",
        "epochs = 10\n",
        "\n",
        "# device \n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize number of inputs (features: 3 X 32 X 32) and outputs (labels: 10)\n",
        "num_inputs = 3 * 32 * 32\n",
        "num_outputs =  10\n",
        "\n",
        "# Initialize weights from normal distribution with mean 0 and standard deviation 0.01\n",
        "W = torch.normal(0,0.01,size = (num_outputs,num_inputs), device = device)\n",
        "\n",
        "# Initialize bias with zeros\n",
        "b = torch.zeros(num_outputs, device = device)\n",
        "\n",
        "loss_function = cross_entropy\n",
        "model = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0_zWk0Ib74K"
      },
      "source": [
        "# <Font color = 'pickle'>**Training Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T06:09:15.462582Z",
          "iopub.status.busy": "2022-09-14T06:09:15.462354Z",
          "iopub.status.idle": "2022-09-14T06:10:27.006093Z",
          "shell.execute_reply": "2022-09-14T06:10:27.005642Z",
          "shell.execute_reply.started": "2022-09-14T06:09:15.462548Z"
        },
        "id": "LckLb_9bhZDw",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0f4788f-7bab-4c25-86b2-2f01e118a407"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<wandb.jupyter.IFrame at 0x7fc6e11db650>"
            ],
            "text/html": [
              "<iframe src=\"https://wandb.ai/pranavshekhar2/dl22_HW2/runs/34u9nqca?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.1300%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n",
            "Epoch : 2 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.0600%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n",
            "Epoch : 3 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.0600%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n",
            "Epoch : 4 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.0600%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n",
            "Epoch : 5 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.0600%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n",
            "Epoch : 6 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.0600%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n",
            "Epoch : 7 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.0600%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n",
            "Epoch : 8 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.0600%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n",
            "Epoch : 9 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.0600%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n",
            "Epoch : 10 / 10\n",
            "Train Loss:  nan | Train Accuracy:  10.0600%\n",
            "Valid Loss:  nan | Valid Accuracy:  9.7600%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%wandb \n",
        "# Train the model\n",
        "train_loss_history, train_acc_history, valid_loss_history, valid_acc_history = train_loop(W, b, \n",
        "                                                                                          num_outputs, \n",
        "                                                                                          train_loader, \n",
        "                                                                                          valid_loader, \n",
        "                                                                                          model, \n",
        "                                                                                          loss_function, \n",
        "                                                                                          epochs, \n",
        "                                                                                          device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG8DWY1NfViW"
      },
      "source": [
        "We can observe that with each epoch, our loss is getting reduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-Cj1f2Qb74K"
      },
      "source": [
        "# <Font color = 'pickle'>**Get Accuracy, Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T06:10:27.006839Z",
          "iopub.status.busy": "2022-09-14T06:10:27.006692Z",
          "iopub.status.idle": "2022-09-14T06:10:28.245886Z",
          "shell.execute_reply": "2022-09-14T06:10:28.245400Z",
          "shell.execute_reply.started": "2022-09-14T06:10:27.006825Z"
        },
        "id": "yw7GhoZuRdIO",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get the prediction and accuracy for the test dataset\n",
        "predictions_test, acc_test = get_acc_pred(test_loader, W, b, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T06:10:28.246988Z",
          "iopub.status.busy": "2022-09-14T06:10:28.246856Z",
          "iopub.status.idle": "2022-09-14T06:10:28.251852Z",
          "shell.execute_reply": "2022-09-14T06:10:28.251386Z",
          "shell.execute_reply.started": "2022-09-14T06:10:28.246976Z"
        },
        "id": "3v2z0oFcRjrF",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3acf74c6-4991-41bf-ab75-8dda8220fb75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy tensor(10.0000, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Print Test Accuracy\n",
        "print('Test accuracy', acc_test * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T06:10:28.252582Z",
          "iopub.status.busy": "2022-09-14T06:10:28.252406Z",
          "iopub.status.idle": "2022-09-14T06:10:28.258308Z",
          "shell.execute_reply": "2022-09-14T06:10:28.257908Z",
          "shell.execute_reply.started": "2022-09-14T06:10:28.252569Z"
        },
        "id": "vcfIlMd3FKAX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "wandb.log({'Test_Acc': acc_test})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caRp4G3ov5fp"
      },
      "source": [
        "# <Font color = 'pickle'>**Confusion Matrix for Test Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZf0pSyQV32m"
      },
      "source": [
        "Now, we will make some visualizations for the predictions that we obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sQH0GvxXnam"
      },
      "source": [
        "We will construct a `confusion matrix` which will help us to visualize the performance of our classification model on the test dataset as we know the true values for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T06:10:28.259147Z",
          "iopub.status.busy": "2022-09-14T06:10:28.258909Z",
          "iopub.status.idle": "2022-09-14T06:10:28.262772Z",
          "shell.execute_reply": "2022-09-14T06:10:28.262286Z",
          "shell.execute_reply.started": "2022-09-14T06:10:28.259129Z"
        },
        "id": "NaiRaPuQYYIV",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get an array containing actual labels\n",
        "testing_labels = np.array(testset.targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-09-14T06:10:28.263594Z",
          "iopub.status.busy": "2022-09-14T06:10:28.263366Z",
          "iopub.status.idle": "2022-09-14T06:10:28.267704Z",
          "shell.execute_reply": "2022-09-14T06:10:28.267278Z",
          "shell.execute_reply.started": "2022-09-14T06:10:28.263579Z"
        },
        "id": "wMuZ1Yl2X47z",
        "outputId": "d032f1b9-e827-4432-9621-c48b21af5892",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "np.unique(testing_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-09-14T06:10:28.268633Z",
          "iopub.status.busy": "2022-09-14T06:10:28.268439Z",
          "iopub.status.idle": "2022-09-14T06:10:28.511956Z",
          "shell.execute_reply": "2022-09-14T06:10:28.511491Z",
          "shell.execute_reply.started": "2022-09-14T06:10:28.268618Z"
        },
        "id": "lAtBZumJcuwX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Log a confusion matrix to W&B\n",
        "wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(\n",
        "                        probs = None,\n",
        "                        y_true = testing_labels,\n",
        "                        preds = predictions_test.to('cpu').numpy(),\n",
        "                        class_names = classes)})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "6717e42d45dc43d48c1d2ca0852ac015",
            "2eede81b3fbf4b679a364c7832d15395",
            "8961751d7a3b4bf8b785ea40d3deb8e0",
            "edba05984d20419899cd6176548ac154",
            "93ece21a4be54ecb84e7960ed98e84ce",
            "9fde749743654b4fb12c1eca00b423bd",
            "3d7903baf45d458382930f9b8f415849",
            "a5fffbebccc443a982c0c3eee03e6589"
          ]
        },
        "execution": {
          "iopub.execute_input": "2022-09-14T06:10:28.512541Z",
          "iopub.status.busy": "2022-09-14T06:10:28.512414Z",
          "iopub.status.idle": "2022-09-14T06:10:42.674747Z",
          "shell.execute_reply": "2022-09-14T06:10:42.674338Z",
          "shell.execute_reply.started": "2022-09-14T06:10:28.512528Z"
        },
        "id": "jIlsxRdPHZYa",
        "outputId": "89e274f7-61e6-4ea7-ceba-92bd3ec3da65",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.006 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.574244…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6717e42d45dc43d48c1d2ca0852ac015"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test_Acc</td><td>▁</td></tr><tr><td>Train Acc :</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Valid Acc :</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test_Acc</td><td>0.1</td></tr><tr><td>Train Acc :</td><td>0.1006</td></tr><tr><td>Train Loss :</td><td>nan</td></tr><tr><td>Valid Acc :</td><td>0.0976</td></tr><tr><td>Valid Loss :</td><td>nan</td></tr><tr><td>learning_rate</td><td>0.5</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">L_0.5</strong>: <a href=\"https://wandb.ai/pranavshekhar2/dl22_HW2/runs/34u9nqca\" target=\"_blank\">https://wandb.ai/pranavshekhar2/dl22_HW2/runs/34u9nqca</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220921_203950-34u9nqca/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2nndkHjVh4v"
      },
      "source": [
        "# My Report\n",
        "\n",
        "- Project URL: https://wandb.ai/pranavshekhar2/dl22_HW2?workspace=user-pranavshekhar2\n",
        "\n",
        "- Conclusion - We get the best test accuracy with learning rate of 0.005."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6717e42d45dc43d48c1d2ca0852ac015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2eede81b3fbf4b679a364c7832d15395",
              "IPY_MODEL_8961751d7a3b4bf8b785ea40d3deb8e0"
            ],
            "layout": "IPY_MODEL_edba05984d20419899cd6176548ac154"
          }
        },
        "2eede81b3fbf4b679a364c7832d15395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93ece21a4be54ecb84e7960ed98e84ce",
            "placeholder": "​",
            "style": "IPY_MODEL_9fde749743654b4fb12c1eca00b423bd",
            "value": "0.016 MB of 0.016 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8961751d7a3b4bf8b785ea40d3deb8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d7903baf45d458382930f9b8f415849",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5fffbebccc443a982c0c3eee03e6589",
            "value": 1
          }
        },
        "edba05984d20419899cd6176548ac154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93ece21a4be54ecb84e7960ed98e84ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fde749743654b4fb12c1eca00b423bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d7903baf45d458382930f9b8f415849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5fffbebccc443a982c0c3eee03e6589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}