{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axN9Fs5aKiQR"
      },
      "source": [
        "# <font color = 'pickle'>**HW3 - 15 Points** </font>\n",
        "\n",
        "1.\tFor Questions (1, 2 and 3) you will submit two files: a) A colab notebook b) A well formatted PDF file.\n",
        "2.\tThe notebook and pdf files should contain all the output.\n",
        "3. For Question 4 - submit a pdf OR ppt file.\n",
        "4.\tName the files as follows : FirstName_hw3.ipynb, FirstName_hw3.pdf\n",
        "5.\tIf the submission requires multiple files name them as follows: FirstName_file1_hw3, FirstName_file2_hw3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea_kC8Jy0sE8"
      },
      "source": [
        "# <font color = 'pickle'>**Q1. Compute Gradient using  PyTorch Autograd - 2 Points**\n",
        "## $f(x,y) = \\frac{x + \\exp(y)}{\\log(x) + (x-y)^3}$\n",
        "Compute dx and dy at x=3 and y=4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyE4WGa2RJTw",
        "outputId": "a0688129-cf7d-478e-f192-5770eee3d1cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.12.1+cu113)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (4.1.1)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4150 sha256=bd73f34a605a70379b220f6d66559009b9ad64689cc7725228ab938867269ae4\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/38/f5/dc4f85c3909051823df49901e72015d2d750bd26b086480ec2\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torchviz import make_dot"
      ],
      "metadata": {
        "id": "lou5H7pQPjmf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([3.0])\n",
        "y = torch.tensor([4.0])"
      ],
      "metadata": {
        "id": "2e8HSnPiPQ0m"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)\n",
        "y.requires_grad_(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyNul6PlQP5U",
        "outputId": "ada955b9-0223-4f87-aa02-780f5ccf1bd5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = (x+(torch.exp(y)))/((torch.log(x))+((x-y)**3))\n",
        "print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em7UkaRzPdQh",
        "outputId": "7ad5693b-98e7-41e3-9d68-6ba67a072e79"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([584.0868], grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making computation graph\n",
        "\n",
        "make_dot(f, params = {'x':x, 'y':y, 'f':f}, show_attrs = True, show_saved = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "pYkzUxgpQlED",
        "outputId": "57b4e04d-d209-49e8-bb35-c22e15988ecf"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f85949dc890>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"459pt\" height=\"489pt\"\n viewBox=\"0.00 0.00 459.00 489.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 485)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-485 455,-485 455,4 -4,4\"/>\n<!-- 140211701163792 -->\n<g id=\"node1\" class=\"node\">\n<title>140211701163792</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"298.5,-30 244.5,-30 244.5,0 298.5,0 298.5,-30\"/>\n<text text-anchor=\"middle\" x=\"271.5\" y=\"-18\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">f</text>\n<text text-anchor=\"middle\" x=\"271.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140211700746512 -->\n<g id=\"node2\" class=\"node\">\n<title>140211700746512</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"343,-118 200,-118 200,-66 343,-66 343,-118\"/>\n<text text-anchor=\"middle\" x=\"271.5\" y=\"-106\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">DivBackward0</text>\n<text text-anchor=\"middle\" x=\"271.5\" y=\"-95\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"271.5\" y=\"-84\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">other: [saved tensor]</text>\n<text text-anchor=\"middle\" x=\"271.5\" y=\"-73\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self : [saved tensor]</text>\n</g>\n<!-- 140211700746512&#45;&gt;140211701163792 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140211700746512&#45;&gt;140211701163792</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M271.5,-65.9313C271.5,-57.6799 271.5,-48.575 271.5,-40.3731\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"275.0001,-40.2587 271.5,-30.2587 268.0001,-40.2588 275.0001,-40.2587\"/>\n</g>\n<!-- 140211700746320 -->\n<g id=\"node3\" class=\"node\">\n<title>140211700746320</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"423,-277.5 334,-277.5 334,-236.5 423,-236.5 423,-277.5\"/>\n<text text-anchor=\"middle\" x=\"378.5\" y=\"-265.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n<text text-anchor=\"middle\" x=\"378.5\" y=\"-254.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"378.5\" y=\"-243.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 140211700746320&#45;&gt;140211700746512 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140211700746320&#45;&gt;140211700746512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M365.1647,-236.4363C347.3712,-208.9976 315.609,-160.0186 294.0565,-126.7834\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.918,-124.7632 288.5404,-118.2773 291.0448,-128.5719 296.918,-124.7632\"/>\n</g>\n<!-- 140211700746448 -->\n<g id=\"node4\" class=\"node\">\n<title>140211700746448</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-415 113,-415 113,-396 214,-396 214,-415\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-403\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140211700746448&#45;&gt;140211700746320 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140211700746448&#45;&gt;140211700746320</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M162.7429,-395.9491C161.8977,-378.229 162.7955,-340.1454 183.5,-319 229.0506,-272.4795 264.3884,-305.4586 325.5,-283 326.8829,-282.4918 328.2775,-281.9587 329.6783,-281.4051\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"331.0939,-284.6067 338.952,-277.5003 328.3774,-278.1553 331.0939,-284.6067\"/>\n</g>\n<!-- 140211700746832 -->\n<g id=\"node10\" class=\"node\">\n<title>140211700746832</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"137,-277.5 0,-277.5 0,-236.5 137,-236.5 137,-277.5\"/>\n<text text-anchor=\"middle\" x=\"68.5\" y=\"-265.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">LogBackward0</text>\n<text text-anchor=\"middle\" x=\"68.5\" y=\"-254.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"68.5\" y=\"-243.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self: [saved tensor]</text>\n</g>\n<!-- 140211700746448&#45;&gt;140211700746832 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140211700746448&#45;&gt;140211700746832</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.2668,-395.7565C143.2464,-373.8404 108.7642,-319.9393 87.1378,-286.1339\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"90.0092,-284.1274 81.6719,-277.5898 84.1126,-287.8997 90.0092,-284.1274\"/>\n</g>\n<!-- 140211701017424 -->\n<g id=\"node12\" class=\"node\">\n<title>140211701017424</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"281,-360 192,-360 192,-319 281,-319 281,-360\"/>\n<text text-anchor=\"middle\" x=\"236.5\" y=\"-348\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">SubBackward0</text>\n<text text-anchor=\"middle\" x=\"236.5\" y=\"-337\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"236.5\" y=\"-326\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 140211700746448&#45;&gt;140211701017424 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140211700746448&#45;&gt;140211701017424</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M174.2714,-395.7615C182.6497,-388.1866 194.7078,-377.2847 205.983,-367.0907\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.5384,-369.4988 213.6089,-360.1961 203.8438,-364.3064 208.5384,-369.4988\"/>\n</g>\n<!-- 140211701234672 -->\n<g id=\"node5\" class=\"node\">\n<title>140211701234672</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"190.5,-481 136.5,-481 136.5,-451 190.5,-451 190.5,-481\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-469\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">x</text>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-458\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140211701234672&#45;&gt;140211700746448 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140211701234672&#45;&gt;140211700746448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-450.7333C163.5,-443.0322 163.5,-433.5977 163.5,-425.3414\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.0001,-425.0864 163.5,-415.0864 160.0001,-425.0864 167.0001,-425.0864\"/>\n</g>\n<!-- 140211700746768 -->\n<g id=\"node6\" class=\"node\">\n<title>140211700746768</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"451,-360 302,-360 302,-319 451,-319 451,-360\"/>\n<text text-anchor=\"middle\" x=\"376.5\" y=\"-348\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">ExpBackward0</text>\n<text text-anchor=\"middle\" x=\"376.5\" y=\"-337\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"376.5\" y=\"-326\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">result: [saved tensor]</text>\n</g>\n<!-- 140211700746768&#45;&gt;140211700746320 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140211700746768&#45;&gt;140211700746320</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M377.0047,-318.6818C377.2314,-309.3288 377.5036,-298.101 377.7533,-287.8031\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"381.2589,-287.6077 378.0024,-277.5258 374.261,-287.438 381.2589,-287.6077\"/>\n</g>\n<!-- 140211700746896 -->\n<g id=\"node7\" class=\"node\">\n<title>140211700746896</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"380,-415 279,-415 279,-396 380,-396 380,-415\"/>\n<text text-anchor=\"middle\" x=\"329.5\" y=\"-403\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140211700746896&#45;&gt;140211700746768 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140211700746896&#45;&gt;140211700746768</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M336.435,-395.7615C341.5699,-388.5508 348.8517,-378.3253 355.8019,-368.5655\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.8121,-370.372 361.7619,-360.1961 353.1102,-366.3115 358.8121,-370.372\"/>\n</g>\n<!-- 140211700746896&#45;&gt;140211701017424 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140211700746896&#45;&gt;140211701017424</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M315.7775,-395.7615C304.7959,-387.9681 288.8519,-376.653 274.1374,-366.2104\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"275.8434,-363.1293 265.6627,-360.1961 271.7921,-368.8379 275.8434,-363.1293\"/>\n</g>\n<!-- 140211701234576 -->\n<g id=\"node8\" class=\"node\">\n<title>140211701234576</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"356.5,-481 302.5,-481 302.5,-451 356.5,-451 356.5,-481\"/>\n<text text-anchor=\"middle\" x=\"329.5\" y=\"-469\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">y</text>\n<text text-anchor=\"middle\" x=\"329.5\" y=\"-458\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140211701234576&#45;&gt;140211700746896 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140211701234576&#45;&gt;140211700746896</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M329.5,-450.7333C329.5,-443.0322 329.5,-433.5977 329.5,-425.3414\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"333.0001,-425.0864 329.5,-415.0864 326.0001,-425.0864 333.0001,-425.0864\"/>\n</g>\n<!-- 140211700746576 -->\n<g id=\"node9\" class=\"node\">\n<title>140211700746576</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"280,-195 191,-195 191,-154 280,-154 280,-195\"/>\n<text text-anchor=\"middle\" x=\"235.5\" y=\"-183\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n<text text-anchor=\"middle\" x=\"235.5\" y=\"-172\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"235.5\" y=\"-161\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">alpha: 1</text>\n</g>\n<!-- 140211700746576&#45;&gt;140211700746512 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140211700746576&#45;&gt;140211700746512</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M244.5843,-153.6818C248.0414,-145.7594 252.0854,-136.4918 255.9726,-127.5836\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"259.3023,-128.7042 260.0939,-118.1389 252.8865,-125.9045 259.3023,-128.7042\"/>\n</g>\n<!-- 140211700746832&#45;&gt;140211700746576 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140211700746832&#45;&gt;140211700746576</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.2104,-236.3946C132.7265,-225.2713 160.7048,-211.4497 184.5071,-199.6911\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.3271,-202.6958 193.7426,-195.1287 183.2267,-196.4199 186.3271,-202.6958\"/>\n</g>\n<!-- 140211700747024 -->\n<g id=\"node11\" class=\"node\">\n<title>140211700747024</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"316,-283 155,-283 155,-231 316,-231 316,-283\"/>\n<text text-anchor=\"middle\" x=\"235.5\" y=\"-271\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">PowBackward0</text>\n<text text-anchor=\"middle\" x=\"235.5\" y=\"-260\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;&#45;</text>\n<text text-anchor=\"middle\" x=\"235.5\" y=\"-249\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">exponent: &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;3</text>\n<text text-anchor=\"middle\" x=\"235.5\" y=\"-238\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">self &#160;&#160;&#160;: [saved tensor]</text>\n</g>\n<!-- 140211700747024&#45;&gt;140211700746576 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140211700747024&#45;&gt;140211700746576</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M235.5,-230.8965C235.5,-222.7976 235.5,-213.794 235.5,-205.4015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.0001,-205.2117 235.5,-195.2117 232.0001,-205.2118 239.0001,-205.2117\"/>\n</g>\n<!-- 140211701017424&#45;&gt;140211700747024 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140211701017424&#45;&gt;140211700747024</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M236.2477,-318.6818C236.1537,-310.9279 236.0441,-301.8855 235.9382,-293.1526\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.4379,-293.0957 235.8168,-283.1389 232.4384,-293.1806 239.4379,-293.0957\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.backward()"
      ],
      "metadata": {
        "id": "tp32cehASDnb"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)\n",
        "print(y.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yWZcORtR0f5",
        "outputId": "551531a8-70e2-455a-be19-4adde7c82458"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-19733.3965])\n",
            "tensor([18322.8477])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYYL_jnG0B3i"
      },
      "source": [
        "# <font color = 'pickle'>**Q2. Regression with autogard (backward() method) 5 points** </font>\n",
        "\n",
        "<font size = 4,  color ='indianred'> **Redo  question 7 from HW1. Now we will use Pytorch's autograd to calculate the gradients instead of manually calculating gradients.**</font>\n",
        "\n",
        "\n",
        "Imagine that you're trying to figure out relationship between two variables x and y . You have some idea but you aren't quite sure yet whether the dependence is linear or quadratic. \n",
        "\n",
        "Your goal is to use least mean squares regression to identify the coefficients for the following three models :\n",
        "\n",
        "1. Quadratic model where $\\mathrm{y} = b + w_1 \\cdot \\mathrm{x} + w_2 \\cdot \\mathrm{x}^2$.\n",
        "1. Linear model where $\\mathrm{y} = b + w_1 \\cdot \\mathrm{x}$.\n",
        "1. Linear model with no bias  where $\\mathrm{y} = w_1 \\cdot \\mathrm{x}$.\n",
        "\n",
        "\n",
        "- You will use batch gradient descent to estimate the model co-efficients. Batch gradient descent uses complete training data at each iteration. \n",
        "- We will implement only training loop (no splitting of data in to training/validation).\n",
        "- The training loop will have only one for loop. We need to iterate over whole data in each epoch. We do not need to create batches.\n",
        "- You may have to try different values of number of epochs/ learning rate to get good results.\n",
        "- <font color = 'indianred'>**You are not allowed to use Pytorch's nn.module or functions from Pytorch. You will write function for loss function (mean sqaured error), and prediction from scratch.**</font>\n",
        "- <font color = 'indianred'>**You will not calculate gradients manually. You will use backward() method to compute gradients.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JShaYAruM_9F"
      },
      "source": [
        "## <font color = 'pickle'> **Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xM9NZIJyJPXJ"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WUcQ0mpp3HNm"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1.5420291, 1.8935232, 2.1603365, 2.5381863, 2.893443, \\\n",
        "                    3.838855, 3.925425, 4.2233696, 4.235571, 4.273397, \\\n",
        "                    4.9332876, 6.4704757, 6.517571, 6.87826, 7.0009003, \\\n",
        "                    7.035741, 7.278681, 7.7561755, 9.121138, 9.728281])\n",
        "y = torch.tensor([63.802246, 80.036026, 91.4903, 108.28776, 122.781975, \\\n",
        "                    161.36314, 166.50816, 176.16772, 180.29395, 179.09758, \\\n",
        "                    206.21027, 272.71857, 272.24033, 289.54745, 293.8488, \\\n",
        "                    295.2281, 306.62274, 327.93243, 383.16296, 408.65967])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = y.view(-1,1)\n",
        "x = x.view(-1,1)\n",
        "x2 = x * x"
      ],
      "metadata": {
        "id": "nY3nQBLQvqWo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_combined = torch.cat((x,x2), dim = 1)"
      ],
      "metadata": {
        "id": "bfbojhz2vx6s"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model - Linear Regresssion\n",
        "\n",
        "def linear_regression(x,w,b, bias):\n",
        "  if bias:\n",
        "    return torch.mm(x,w.T) + b\n",
        "  else:\n",
        "    return torch.mm(x,w.T)"
      ],
      "metadata": {
        "id": "4JdMlXLKvinw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss Function\n",
        "\n",
        "def mean_square_loss(y, yhat):\n",
        "  error = yhat - y\n",
        "  sum_square_loss = error.T@error\n",
        "  return sum_square_loss/len(y)\n"
      ],
      "metadata": {
        "id": "tBNj_CpTwet8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Updating the parameters\n",
        "\n",
        "def sgd_step(params, param_grads, learning_rate):\n",
        "  for param, param_grad in zip(params, param_grads):\n",
        "    param -= learning_rate*param_grad"
      ],
      "metadata": {
        "id": "o-RkfYToxZvG"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Loop\n",
        "\n",
        "def train(epochs, x,y, n_outs, bias, loss_function, log_interval, learning_rate):\n",
        "  loss_epoch = []\n",
        "  n_ins = x.shape[-1]\n",
        "  w = torch.normal(0, 0.01, size=(n_outs, n_ins), requires_grad=True)\n",
        "  b = torch.zeros(n_outs, requires_grad=True)\n",
        "  if bias:\n",
        "    params = (w, b)\n",
        "  else:\n",
        "    params = w\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    \n",
        "    # Step1: forward pass\n",
        "    y_hat = linear_regression(x, w, b, bias)\n",
        "\n",
        "    # Step2 : Loss\n",
        "    loss = loss_function(y_hat, y)\n",
        "    loss.backward()\n",
        "\n",
        "    #Calculate Gradients\n",
        "    if bias:\n",
        "      param_grads = (w.grad,b.grad)\n",
        "    else:\n",
        "      param_grads = w.grad\n",
        "\n",
        "    # Update parameters\n",
        "    with torch.no_grad():\n",
        "      sgd_step(params, param_grads, learning_rate)  \n",
        "   \n",
        "    if bias:\n",
        "      w.grad.zero_()\n",
        "      b.grad.zero_()\n",
        "    else:\n",
        "      w.grad.zero_()\n",
        "\n",
        "    if(epoch % log_interval ==0):\n",
        "      print(f'epoch: {epoch + 1} --> loss {loss.item()}')\n",
        "\n",
        "  return (w, b)"
      ],
      "metadata": {
        "id": "f3kWAcEQxF7t"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 1 - Training and Checking results"
      ],
      "metadata": {
        "id": "uZKrb4ZqneK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1  \n",
        "loss_function = mean_square_loss\n",
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 100000\n",
        "LOG_INTERVAL= 10000\n",
        "N_OUTS = 1\n",
        "BIAS = True\n",
        "\n",
        "w1, b1 = train(EPOCHS, x_combined, y,  N_OUTS, BIAS, loss_function, LOG_INTERVAL, LEARNING_RATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojKjBgeSna4O",
        "outputId": "9d23980d-bb1b-41e5-82ae-d1b2e750024d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 --> loss 57724.1640625\n",
            "epoch: 10001 --> loss 5.004037380218506\n",
            "epoch: 20001 --> loss 3.0955586433410645\n",
            "epoch: 30001 --> loss 2.137913227081299\n",
            "epoch: 40001 --> loss 1.6573288440704346\n",
            "epoch: 50001 --> loss 1.4161760807037354\n",
            "epoch: 60001 --> loss 1.294985055923462\n",
            "epoch: 70001 --> loss 1.2341334819793701\n",
            "epoch: 80001 --> loss 1.2036077976226807\n",
            "epoch: 90001 --> loss 1.1882108449935913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' Weights {w1}, \\nBias: {b1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLs4xEbe_SNo",
        "outputId": "2e1251ea-2648-41db-e58f-889583a7aad9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Weights tensor([[4.1796e+01, 1.4833e-02]], requires_grad=True), \n",
            "Bias: tensor([0.9774], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2\n",
        "\n",
        "loss_function = mean_square_loss\n",
        "LEARNING_RATE = 0.01\n",
        "EPOCHS = 1000\n",
        "LOG_INTERVAL = 100\n",
        "N_OUTS = 1\n",
        "BIAS = True\n",
        "\n",
        "w2,b2 = train(EPOCHS, x, y, N_OUTS, BIAS, loss_function, LOG_INTERVAL, LEARNING_RATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XujDipfH_AYG",
        "outputId": "a1aeb722-ab3c-4110-bf84-9cffe33f43a8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 --> loss 57908.51171875\n",
            "epoch: 101 --> loss 4.353393077850342\n",
            "epoch: 201 --> loss 2.8058464527130127\n",
            "epoch: 301 --> loss 2.0112340450286865\n",
            "epoch: 401 --> loss 1.6032235622406006\n",
            "epoch: 501 --> loss 1.3937246799468994\n",
            "epoch: 601 --> loss 1.2861621379852295\n",
            "epoch: 701 --> loss 1.2309223413467407\n",
            "epoch: 801 --> loss 1.2025630474090576\n",
            "epoch: 901 --> loss 1.188001275062561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' Weights {w2}, \\nBias: {b2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MniOTzAT_Awd",
        "outputId": "bafda917-6c71-4e11-fe3c-4cdb9c38c827"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Weights tensor([[41.9377]], requires_grad=True), \n",
            "Bias: tensor([0.7466], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 3\n",
        "\n",
        "loss_function = mean_square_loss\n",
        "LEARNING_RATE = 0.01\n",
        "EPOCHS = 10\n",
        "LOG_INTERVAL = 1\n",
        "N_OUTS = 1\n",
        "BIAS = False\n",
        "\n",
        "w3, b3 = train(EPOCHS, x, y,  N_OUTS, BIAS, loss_function, LOG_INTERVAL, LEARNING_RATE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ8CQudO_0Pd",
        "outputId": "c5f5a9c7-d5a5-48e2-99f7-181a593bb1df"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 --> loss 57962.7734375\n",
            "epoch: 2 --> loss 6895.7265625\n",
            "epoch: 3 --> loss 821.3201293945312\n",
            "epoch: 4 --> loss 98.77147674560547\n",
            "epoch: 5 --> loss 12.824447631835938\n",
            "epoch: 6 --> loss 2.601112127304077\n",
            "epoch: 7 --> loss 1.3850189447402954\n",
            "epoch: 8 --> loss 1.2403712272644043\n",
            "epoch: 9 --> loss 1.223166584968567\n",
            "epoch: 10 --> loss 1.2211220264434814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f' Weights {w3}, \\nBias: {b3}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvWHHcXlBbDl",
        "outputId": "d473b71c-f4da-4d45-c647-449ebfadd4e0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Weights tensor([[42.0557]], requires_grad=True), \n",
            "Bias: tensor([0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX5yKE-t0sEn"
      },
      "source": [
        "# <font color = 'pickle'>**Q 3. Numerical Precision - 3 Points**\n",
        "\n",
        "Given scalars `x` and `y`, implement the following `log_exp` function such that it returns \n",
        "$$-\\log\\left(\\frac{e^x}{e^x+e^y}\\right)$$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-29T22:48:56.206890Z",
          "start_time": "2019-01-29T22:48:56.202996Z"
        },
        "id": "bWMtemrU0sEn"
      },
      "outputs": [],
      "source": [
        "#Question\n",
        "def log_exp(x, y):\n",
        "    return -torch.log(torch.exp(x)/(torch.exp(x) + torch.exp(y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vnhIMm_0sEq"
      },
      "source": [
        "Test your codes with normal inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-29T22:48:56.215579Z",
          "start_time": "2019-01-29T22:48:56.209659Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPTgyJUP0sEq",
        "outputId": "2bbe1d0f-3fb9-4f69-b25b-06b811789d96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.3133])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "x, y = torch.tensor([2.0]), torch.tensor([3.0])\n",
        "z = log_exp(x, y)\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIxDzHy40sEu"
      },
      "source": [
        "Now implement a function to compute $\\partial z/\\partial x$ and $\\partial z/\\partial y$ with `autograd`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-29T22:48:56.223303Z",
          "start_time": "2019-01-29T22:48:56.218056Z"
        },
        "id": "7EOGdkq_0sEu"
      },
      "outputs": [],
      "source": [
        "# function should print the gradients dx and dy \n",
        "def grad(forward_func, x, y): \n",
        "  \n",
        "  x.requires_grad_()\n",
        "  y.requires_grad_()\n",
        "  z = forward_func(x,y)\n",
        "  z.backward()\n",
        "  \n",
        "  print(\"x.grad = \", x.grad)\n",
        "  print(\"y.grad = \", y.grad)\n",
        "  x.grad.data.zero_()\n",
        "  y.grad.data.zero_()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySyDOwxN0sEz"
      },
      "source": [
        "Test your codes, it should print the results nicely. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-29T22:48:56.267165Z",
          "start_time": "2019-01-29T22:48:56.227035Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT3QgbCB0sE0",
        "outputId": "677636de-18dd-462d-f26d-913444bab60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad =  tensor([-0.7311])\n",
            "y.grad =  tensor([0.7311])\n"
          ]
        }
      ],
      "source": [
        "grad(log_exp, x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fquEJMkU0sE2"
      },
      "source": [
        "But now let's try some \"hard\" inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-29T22:48:56.285842Z",
          "start_time": "2019-01-29T22:48:56.274079Z"
        },
        "id": "MlDABmit0sE3"
      },
      "outputs": [],
      "source": [
        "x, y = torch.tensor([50.0]), torch.tensor([100.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwgzqhBmIoIi",
        "outputId": "63720e95-60de-455c-9044-596c402799ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad =  tensor([nan])\n",
            "y.grad =  tensor([nan])\n"
          ]
        }
      ],
      "source": [
        "grad(log_exp, x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXXpskJNByXD",
        "outputId": "f0e0b73b-8732-45b1-cf98-7634f4014e2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([inf])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "torch.exp(torch.tensor([100.0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O97Bv7y0sE6"
      },
      "source": [
        "Does your code return correct results? If not, try to understand the reason. (Hint, evaluate `exp(100)`). Now develop a new function `stable_log_exp` that is identical to `log_exp` in math, but returns a more numerical stable result.\n",
        "<br> Hint: (1) $\\log\\left(\\frac{x}{y}\\right) = log ({x}) -log({y})$\n",
        "<br> Hint: (2) See logsum Trick - https://www.xarg.org/2016/06/the-log-sum-exp-trick-in-machine-learning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-29T22:48:56.305595Z",
          "start_time": "2019-01-29T22:48:56.293399Z"
        },
        "id": "bzNFL9jG0sE6"
      },
      "outputs": [],
      "source": [
        "#Simplification of the expression is attached in PDF file\n",
        "#Used 2 hints - log(x/y) = log(x)-log(y) and log(a+b) = log(a) + log(1+(b/a))\n",
        "\n",
        "\n",
        "\n",
        "def stable_log_exp(x, y):\n",
        "    return torch.log(1+ torch.exp(y-x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVp9w2DKH-D_",
        "outputId": "c83894e4-a759-4423-e7ca-2d83881cec19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad =  tensor([-1.])\n",
            "y.grad =  tensor([1.])\n"
          ]
        }
      ],
      "source": [
        "grad(stable_log_exp, x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbtZq01Y_iqP"
      },
      "source": [
        "# <font color = 'pickle'>**Q4 : Manual Backpropogation (5 Points)**\n",
        "\n",
        "For the network below update the weights using back propogation. \n",
        "\n",
        "<img src = \"https://drive.google.com/uc?export=view&id=1e1EI-N773mUtQJ0SQx5wlJJ1RaIQ4dZ2\" width =600 >\n",
        "\n",
        "- X1, x2 are inputs. The values of the inputs are provided.\n",
        "- h1, h2 are hidden neurons. You will need to calculate the values of h1 and h2 in forward pass.\n",
        "- o1 and o2 are outputs. 0.01 and 0.99 are the true values of the output. You will calculate the predicted values of o1 and o1 in forward pass.\n",
        "- W1-W8 are weights. The initial values are provided to you. You will need to calculate the updated values in backward pass.\n",
        "- bh1, bh2, bo1, bo2 are bias terms. The initial values are provided. You will need to calculate the updated values in backward pass.\n",
        "\n",
        "- You will apply sigmoid activation on hidden layer.\n",
        "- You will apply Linear activation function on output neurons.\n",
        "- You will use the  squared error as the loss function. \n",
        "where <br>$ E_1 =1/2 *(\\hat{o_1}-o_1)^2 $ <br> \n",
        "$ E_2 =1/2 *(\\hat{o_2}-o_2)^2 $ <br>  $ E = E_1 + E_2$\n",
        "\n",
        "Here $E$ is the total loss. $\\hat{o_2}$ and $\\hat{o_2}$ are predicted values of $o_1$ and $o_2$.\n",
        " \n",
        "- <font color ='indianred'> **Assume a Learning Rate of 10.**\n",
        "    \n",
        "\n",
        "<font color ='indianred'> **Requirements**\n",
        "- Show caluclations for one forward and one backward pass.\n",
        "- Show all the steps of your calculations. You will get partial credit for the steps even if the final answers are not accurate.\n",
        "- You will do this question manually.\n",
        "- For this question you can submit - ppt  or pdf file (pdf of handwritten calculations)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}